{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "avocado = pd.read_csv(\"/home/andy/datasets/avocado.csv\", parse_dates=['Date'])\n",
    "telco_churn = pd.read_csv(\"/home/andy/datasets/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "titanic = pd.read_csv(\"fml/tests/titanic.csv\")\n",
    "adult = pd.read_csv(\"http://github.com/amueller/ml-training-advanced/raw/master/notebooks/data/adult.csv\", na_values=['grrr'])\n",
    "adult_nan = pd.read_csv(\"http://github.com/amueller/ml-training-advanced/raw/master/notebooks/data/adult.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fml.preprocessing import detect_types_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0        32561\n",
      "age                  73\n",
      "workclass             9\n",
      "education            16\n",
      "education-num        16\n",
      "marital-status        7\n",
      "occupation           15\n",
      "relationship          6\n",
      "race                  5\n",
      "gender                2\n",
      "capital-gain        119\n",
      "capital-loss         92\n",
      "hours-per-week       94\n",
      "native-country       42\n",
      "income                2\n",
      "dtype: int64\n",
      "Detected feature types:\n",
      "0 float, 6 int, 9 object, 0 date, 0 other\n",
      "Interpreted as:\n",
      "continuous      1\n",
      "dirty_float     0\n",
      "low_card_int    5\n",
      "categorical     2\n",
      "date            0\n",
      "free_string     0\n",
      "useless         7\n",
      "dtype: int64\n",
      "WARN dropped columns (too many unique values): ['education', 'marital-status', 'native-country', 'occupation', 'race', 'relationship', 'workclass']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          continuous\n",
       "age               low_card_int\n",
       "capital-gain      low_card_int\n",
       "capital-loss      low_card_int\n",
       "education              useless\n",
       "education-num     low_card_int\n",
       "gender             categorical\n",
       "hours-per-week    low_card_int\n",
       "income             categorical\n",
       "marital-status         useless\n",
       "native-country         useless\n",
       "occupation             useless\n",
       "race                   useless\n",
       "relationship           useless\n",
       "workclass              useless\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_types_dataframe(adult, verbose=10).T.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5901\n",
       "1    1142\n",
       "Name: SeniorCitizen, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telco_churn.SeniorCitizen.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn               categorical\n",
       "Contract                useless\n",
       "Dependents          categorical\n",
       "DeviceProtection        useless\n",
       "InternetService         useless\n",
       "MonthlyCharges       continuous\n",
       "MultipleLines           useless\n",
       "OnlineBackup            useless\n",
       "OnlineSecurity          useless\n",
       "PaperlessBilling    categorical\n",
       "Partner             categorical\n",
       "PaymentMethod           useless\n",
       "PhoneService        categorical\n",
       "SeniorCitizen           useless\n",
       "StreamingMovies         useless\n",
       "StreamingTV             useless\n",
       "TechSupport             useless\n",
       "TotalCharges        dirty_float\n",
       "customerID          free_string\n",
       "gender              categorical\n",
       "tenure               continuous\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_types_dataframe(telco_churn).T.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4046              continuous\n",
       "4225              continuous\n",
       "4770              continuous\n",
       "AveragePrice      continuous\n",
       "Date                    date\n",
       "Large Bags        continuous\n",
       "Small Bags        continuous\n",
       "Total Bags        continuous\n",
       "Total Volume      continuous\n",
       "Unnamed: 0      low_card_int\n",
       "XLarge Bags       continuous\n",
       "region               useless\n",
       "type             categorical\n",
       "year            low_card_int\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_types_dataframe(avocado).T.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fml.preprocessing import FriendlyPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp = FriendlyPreprocessor(verbose=10)\n",
    "# sp.fit(avocado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = telco_churn.Churn\n",
    "X = telco_churn.drop(\"Churn\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     0.73463\n",
       "Yes    0.26537\n",
       "Name: Churn, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts() / y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fml.models import FriendlyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected feature types:\n",
      "1 float, 2 int, 17 object, 0 date, 0 other\n",
      "Interpreted as:\n",
      "3 continuous, 15 categorical, 0 date, 1 dirty float, 1 dropped\n",
      "DummyClassifier(strategy='prior')\n",
      "accuracy: 0.7346    average_precision: 0.2654    recall_macro: 0.5000    roc_auc: 0.5000    \n",
      "new best: 0.5000\n",
      "GaussianNB()\n",
      "accuracy: 0.6320    average_precision: 0.6081    recall_macro: 0.7169    roc_auc: 0.8182    \n",
      "new best: 0.7169\n",
      "MultinomialNB()\n",
      "accuracy: 0.7177    average_precision: 0.6067    recall_macro: 0.7481    roc_auc: 0.8174    \n",
      "new best: 0.7481\n",
      "DecisionTreeClassifier(class_weight='balanced', max_depth=1)\n",
      "accuracy: 0.6544    average_precision: 0.4087    recall_macro: 0.7282    roc_auc: 0.7282    \n",
      "DecisionTreeClassifier(class_weight='balanced', max_depth=5)\n",
      "accuracy: 0.7238    average_precision: 0.6105    recall_macro: 0.7510    roc_auc: 0.8293    \n",
      "new best: 0.7510\n",
      "DecisionTreeClassifier(class_weight='balanced', min_impurity_decrease=0.01)\n",
      "accuracy: 0.7233    average_precision: 0.4837    recall_macro: 0.7440    roc_auc: 0.7804    \n",
      "LogisticRegression(C=0.1, class_weight='balanced', solver='lbfgs')\n",
      "accuracy: 0.7468    average_precision: 0.6542    recall_macro: 0.7628    roc_auc: 0.8448    \n",
      "new best: 0.7628\n"
     ]
    }
   ],
   "source": [
    "# %%prun -s cumulative -l 100 -D test.prof\n",
    "fc = FriendlyClassifier().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = pd.read_csv(\"http://github.com/amueller/ml-training-advanced/raw/master/notebooks/data/adult.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import fetch_openml\n",
    "# adult = fetch_openml(\"adult-census\")\n",
    "# adult_df = pd.DataFrame(adult.data, columns=adult.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = adult.income\n",
    "X = adult.drop(\"income\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'age', 'workclass', 'education', 'education-num',\n",
       "       'marital-status', 'occupation', 'relationship', 'race', 'gender',\n",
       "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 14)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>continuous</th>\n",
       "      <th>categorical</th>\n",
       "      <th>date</th>\n",
       "      <th>dirty_float</th>\n",
       "      <th>useless</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-gain</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-loss</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education-num</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital-status</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                continuous  categorical   date  dirty_float  useless\n",
       "Unnamed: 0            True        False  False        False    False\n",
       "age                   True         True  False        False    False\n",
       "capital-gain          True         True  False        False    False\n",
       "capital-loss          True         True  False        False    False\n",
       "education            False         True  False        False    False\n",
       "education-num         True         True  False        False    False\n",
       "gender               False         True  False        False    False\n",
       "hours-per-week        True         True  False        False    False\n",
       "marital-status       False         True  False        False    False\n",
       "native-country       False         True  False        False    False\n",
       "occupation           False         True  False        False    False\n",
       "race                 False         True  False        False    False\n",
       "relationship         False         True  False        False    False\n",
       "workclass            False         True  False        False    False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fml.preprocessing import detect_types_dataframe\n",
    "detect_types_dataframe(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        32561\n",
       "age                  73\n",
       "workclass             9\n",
       "education            16\n",
       "education-num        16\n",
       "marital-status        7\n",
       "occupation           15\n",
       "relationship          6\n",
       "race                  5\n",
       "gender                2\n",
       "capital-gain        119\n",
       "capital-loss         92\n",
       "hours-per-week       94\n",
       "native-country       42\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_values = X.apply(lambda x: x.nunique())\n",
    "n_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected feature types:\n",
      "0 float, 6 int, 8 object, 0 date, 0 other\n",
      "Interpreted as:\n",
      "6 continuous, 13 categorical, 0 date, 0 dirty float, 0 dropped\n",
      "DummyClassifier(strategy='prior')\n",
      "accuracy: 0.7592    average_precision: 0.2408    recall_macro: 0.5000    roc_auc: 0.5000    \n",
      "new best: 0.5000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fb60361265ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFriendlyClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/checkout/fml/fml/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_best_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfast_ests\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_preproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;31m# make scoring configurable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mthis_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'recall_macro'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/checkout/fml/fml/models.py\u001b[0m in \u001b[0;36m_evaluate_one\u001b[0;34m(self, estimator, data_preproc, scorers)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_preproc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0;31m# fit_time = time.time() - start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/checkout/scikit-learn/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \"\"\"\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[1;32m    192\u001b[0m                                  sample_weight=sample_weight)\n",
      "\u001b[0;32m~/checkout/scikit-learn/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    748\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/checkout/scikit-learn/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    510\u001b[0m                                       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m                                       \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                                       accept_large_sparse=accept_large_sparse)\n\u001b[0m\u001b[1;32m    513\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;31m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/checkout/scikit-learn/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         raise TypeError('A sparse matrix was passed, but dense '\n\u001b[0m\u001b[1;32m    314\u001b[0m                         \u001b[0;34m'data is required. Use X.toarray() to '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                         'convert to a dense numpy array.')\n",
      "\u001b[0;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "fc = FriendlyClassifier().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fml.preprocessing import detect_types_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf = detect_types_dataframe(X, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Contract             True\n",
       "Dependents           True\n",
       "DeviceProtection     True\n",
       "InternetService      True\n",
       "MonthlyCharges      False\n",
       "MultipleLines        True\n",
       "OnlineBackup         True\n",
       "OnlineSecurity       True\n",
       "PaperlessBilling     True\n",
       "Partner              True\n",
       "PaymentMethod        True\n",
       "PhoneService         True\n",
       "SeniorCitizen       False\n",
       "StreamingMovies      True\n",
       "StreamingTV          True\n",
       "TechSupport          True\n",
       "TotalCharges        False\n",
       "customerID          False\n",
       "gender               True\n",
       "tenure               True\n",
       "Name: categorical, dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdf.categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Contract: True Dependents: True DeviceProtection: True InternetService: True MonthlyCharges: False MultipleLines: True OnlineBackup: True OnlineSecurity: True PaperlessBilling: True Partner: True PaymentMethod: True PhoneService: True SeniorCitizen: False StreamingMovies: True StreamingTV: True TechSupport: True TotalCharges: False customerID: False gender: True tenure: True '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(\"{}: {} \".format(a, b) for a, b in asdf.categorical.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7043, 119)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cleanish.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7043, 192)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = FriendlyPreprocessor()\n",
    "fp.fit_transform(X_cleanish).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier(constant=None, random_state=None, strategy='prior')\n",
      "fit_time                   0.004455\n",
      "score_time                 0.010412\n",
      "test_accuracy              0.734630\n",
      "train_accuracy             0.734630\n",
      "test_average_precision     0.265370\n",
      "train_average_precision    0.265370\n",
      "test_roc_auc               0.500000\n",
      "train_roc_auc              0.500000\n",
      "test_precision_macro       0.367315\n",
      "train_precision_macro      0.367315\n",
      "dtype: float64\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "fit_time                   0.098654\n",
      "score_time                 0.050067\n",
      "test_accuracy              0.596049\n",
      "train_accuracy             0.610500\n",
      "test_average_precision     0.420463\n",
      "train_average_precision    0.439988\n",
      "test_roc_auc               0.724284\n",
      "train_roc_auc              0.747796\n",
      "test_precision_macro       0.642855\n",
      "train_precision_macro      0.656280\n",
      "dtype: float64\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "fit_time                   0.100408\n",
      "score_time                 0.044273\n",
      "test_accuracy              0.739316\n",
      "train_accuracy             0.742865\n",
      "test_average_precision     0.631536\n",
      "train_average_precision    0.639603\n",
      "test_roc_auc               0.825740\n",
      "train_roc_auc              0.831570\n",
      "test_precision_macro       0.705550\n",
      "train_precision_macro      0.709238\n",
      "dtype: float64\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "fit_time                   0.086498\n",
      "score_time                 0.041465\n",
      "test_accuracy              0.654410\n",
      "train_accuracy             0.654409\n",
      "test_average_precision     0.408651\n",
      "train_average_precision    0.408584\n",
      "test_roc_auc               0.728213\n",
      "train_roc_auc              0.728216\n",
      "test_precision_macro       0.679810\n",
      "train_precision_macro      0.679775\n",
      "dtype: float64\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "fit_time                   0.109735\n",
      "score_time                 0.040002\n",
      "test_accuracy              0.724546\n",
      "train_accuracy             0.747764\n",
      "test_average_precision     0.605022\n",
      "train_average_precision    0.642543\n",
      "test_roc_auc               0.827966\n",
      "train_roc_auc              0.852527\n",
      "test_precision_macro       0.698869\n",
      "train_precision_macro      0.720309\n",
      "dtype: float64\n",
      " \n",
      "*** Profile stats marshalled to file 'test.prof'. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         1538259 function calls (1514676 primitive calls) in 6.158 seconds\n",
       "\n",
       "   Ordered by: cumulative time\n",
       "   List reduced from 1420 to 100 due to restriction <100>\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "        1    0.000    0.000    6.158    6.158 {built-in method builtins.exec}\n",
       "        1    0.000    0.000    6.157    6.157 <string>:2(<module>)\n",
       "        1    0.000    0.000    5.885    5.885 models.py:25(fit)\n",
       "        5    0.000    0.000    5.845    1.169 models.py:65(_evaluate_one)\n",
       "        5    0.000    0.000    5.835    1.167 _validation.py:40(cross_validate)\n",
       "    205/5    0.009    0.000    5.821    1.164 parallel.py:932(__call__)\n",
       "   630/30    0.005    0.000    5.820    0.194 parallel.py:801(dispatch_one_batch)\n",
       "   425/25    0.004    0.000    5.757    0.230 parallel.py:764(_dispatch)\n",
       "   425/25    0.001    0.000    5.757    0.230 _parallel_backends.py:180(apply_async)\n",
       "   425/25    0.001    0.000    5.757    0.230 _parallel_backends.py:542(__init__)\n",
       "   425/25    0.003    0.000    5.757    0.230 parallel.py:258(__call__)\n",
       "   425/25    0.002    0.000    5.756    0.230 parallel.py:260(<listcomp>)\n",
       "       25    0.001    0.000    5.755    0.230 _validation.py:390(_fit_and_score)\n",
       "       50    0.000    0.000    3.756    0.075 _validation.py:582(_score)\n",
       "       50    0.002    0.000    3.756    0.075 _validation.py:611(_multimetric_score)\n",
       "      200    0.002    0.000    2.700    0.014 _column_transformer.py:380(_fit_transform)\n",
       "      160    0.001    0.000    2.306    0.014 metaestimators.py:118(<lambda>)\n",
       "      180    0.002    0.000    2.039    0.011 preprocessing.py:309(transform)\n",
       "      180    0.002    0.000    2.036    0.011 _column_transformer.py:473(transform)\n",
       "       20    0.000    0.000    1.915    0.096 pipeline.py:239(fit)\n",
       "      100    0.002    0.000    1.893    0.019 scorer.py:142(__call__)\n",
       "      100    0.001    0.000    1.860    0.019 scorer.py:67(__call__)\n",
       "    71/26    0.001    0.000    1.461    0.056 base.py:438(fit_transform)\n",
       "    40/20    0.001    0.000    1.439    0.072 pipeline.py:190(_fit)\n",
       "     2152    0.012    0.000    1.439    0.001 arraysetops.py:113(unique)\n",
       "    50/25    0.000    0.000    1.436    0.057 memory.py:328(__call__)\n",
       "    90/25    0.000    0.000    1.436    0.057 pipeline.py:612(_fit_transform_one)\n",
       "     2152    0.077    0.000    1.422    0.001 arraysetops.py:256(_unique1d)\n",
       "      360    0.001    0.000    1.239    0.003 pipeline.py:604(_transform_one)\n",
       "     2188    1.237    0.001    1.237    0.001 {method 'sort' of 'numpy.ndarray' objects}\n",
       "       80    0.001    0.000    1.183    0.015 pipeline.py:364(predict_proba)\n",
       "       80    0.001    0.000    1.123    0.014 pipeline.py:306(predict)\n",
       "       20    0.001    0.000    1.112    0.056 preprocessing.py:239(fit)\n",
       "       20    0.000    0.000    1.091    0.055 _column_transformer.py:400(fit)\n",
       "       20    0.000    0.000    1.091    0.055 _column_transformer.py:423(fit_transform)\n",
       "      200    0.006    0.000    1.004    0.005 impute.py:353(transform)\n",
       "      180    0.002    0.000    0.958    0.005 pipeline.py:447(_transform)\n",
       "     1004    0.022    0.000    0.950    0.001 validation.py:357(check_array)\n",
       "       20    0.000    0.000    0.905    0.045 pipeline.py:270(fit_transform)\n",
       "      796    0.011    0.000    0.814    0.001 multiclass.py:174(type_of_target)\n",
       "       20    0.000    0.000    0.706    0.035 impute.py:210(fit)\n",
       "       20    0.000    0.000    0.639    0.032 impute.py:301(_dense_fit)\n",
       "       20    0.000    0.000    0.628    0.031 extras.py:617(median)\n",
       "       20    0.000    0.000    0.628    0.031 function_base.py:3982(_ureduce)\n",
       "       20    0.002    0.000    0.627    0.031 extras.py:699(_median)\n",
       "      220    0.002    0.000    0.589    0.003 impute.py:171(_validate_input)\n",
       "       20    0.000    0.000    0.584    0.029 core.py:6685(sort)\n",
       "       20    0.001    0.000    0.560    0.028 core.py:5484(sort)\n",
       "      630    0.003    0.000    0.517    0.001 parallel.py:252(__init__)\n",
       "      100    0.001    0.000    0.484    0.005 classification.py:44(_check_targets)\n",
       "       50    0.000    0.000    0.479    0.010 classification.py:1173(precision_score)\n",
       "       50    0.004    0.000    0.479    0.010 classification.py:882(precision_recall_fscore_support)\n",
       "      600    0.002    0.000    0.453    0.001 _column_transformer.py:390(<genexpr>)\n",
       "     7796    0.451    0.000    0.451    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
       "      510    0.003    0.000    0.427    0.001 indexing.py:1463(__getitem__)\n",
       "29606/27648    0.209    0.000    0.387    0.000 {built-in method numpy.core.multiarray.array}\n",
       "     1602    0.001    0.000    0.368    0.000 _methods.py:31(_sum)\n",
       "      200    0.001    0.000    0.362    0.002 _column_transformer.py:502(_hstack)\n",
       "      400    0.003    0.000    0.359    0.001 _column_transformer.py:569(_get_column)\n",
       "     3719    0.357    0.000    0.357    0.000 {built-in method numpy.core.multiarray.concatenate}\n",
       "      406    0.004    0.000    0.343    0.001 indexing.py:868(_getitem_tuple)\n",
       "      673    0.002    0.000    0.336    0.000 generic.py:4563(values)\n",
       "      457    0.005    0.000    0.335    0.001 generic.py:2783(_take)\n",
       "      255    0.001    0.000    0.330    0.001 shape_base.py:236(hstack)\n",
       "      673    0.003    0.000    0.328    0.000 internals.py:3922(as_array)\n",
       "      442    0.245    0.001    0.321    0.001 internals.py:3953(_interleave)\n",
       "       10    0.000    0.000    0.316    0.032 tree.py:759(fit)\n",
       "      578    0.316    0.001    0.316    0.001 {method 'argsort' of 'numpy.ndarray' objects}\n",
       "       10    0.001    0.000    0.316    0.032 tree.py:111(fit)\n",
       "      201    0.001    0.000    0.313    0.002 _encoders.py:581(transform)\n",
       "      201    0.009    0.000    0.312    0.002 _encoders.py:551(_transform_new)\n",
       "      408    0.002    0.000    0.309    0.001 indexing.py:1854(_getitem_axis)\n",
       "       20    0.000    0.000    0.303    0.015 core.py:5326(argsort)\n",
       "     2590    0.004    0.000    0.300    0.000 {pandas._libs.lib.values_from_object}\n",
       "      457    0.006    0.000    0.297    0.001 internals.py:4518(take)\n",
       "      663    0.001    0.000    0.296    0.000 generic.py:1605(__array__)\n",
       "      663    0.001    0.000    0.294    0.000 generic.py:4645(get_values)\n",
       "       50    0.000    0.000    0.293    0.006 ranking.py:130(average_precision_score)\n",
       "      406    0.002    0.000    0.291    0.001 indexing.py:1489(_getbool_axis)\n",
       "      330    0.286    0.001    0.286    0.001 {built-in method numpy.core.multiarray.where}\n",
       "       50    0.001    0.000    0.286    0.006 ranking.py:239(roc_auc_score)\n",
       "      100    0.002    0.000    0.284    0.003 arraysetops.py:590(union1d)\n",
       "      100    0.001    0.000    0.281    0.003 base.py:23(_average_binary_score)\n",
       "        1    0.000    0.000    0.273    0.273 preprocessing.py:163(safe_cleanup)\n",
       "     1218    0.087    0.000    0.269    0.000 validation.py:40(_assert_all_finite)\n",
       "       40    0.208    0.005    0.261    0.007 naive_bayes.py:429(_joint_log_likelihood)\n",
       "      465    0.003    0.000    0.254    0.001 internals.py:4388(reindex_indexer)\n",
       "       50    0.007    0.000    0.253    0.005 classification.py:115(accuracy_score)\n",
       "        2    0.001    0.001    0.249    0.125 preprocessing.py:48(detect_types_dataframe)\n",
       "    11827    0.005    0.000    0.246    0.000 numeric.py:424(asarray)\n",
       "        3    0.000    0.000    0.226    0.075 frame.py:5837(apply)\n",
       "        3    0.000    0.000    0.226    0.075 apply.py:311(get_result)\n",
       "        3    0.000    0.000    0.226    0.075 apply.py:105(get_result)\n",
       "        3    0.000    0.000    0.226    0.075 apply.py:219(apply_standard)\n",
       "       10    0.225    0.022    0.225    0.022 {method 'build' of 'sklearn.tree._tree.DepthFirstTreeBuilder' objects}\n",
       "       80    0.212    0.003    0.217    0.003 core.py:3186(__getitem__)\n",
       "     2712    0.027    0.000    0.205    0.000 algorithms.py:1548(take_nd)\n",
       "       60    0.002    0.000    0.199    0.003 multiclass.py:42(unique_labels)\n",
       "     1017    0.002    0.000    0.196    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
       "      100    0.010    0.000    0.191    0.002 ranking.py:354(_binary_clf_curve)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%prun -s cumulative -l 100 -D test.prof\n",
    "X_cleanish = safe_cleanup(X, onehot=True)\n",
    "fc = FriendlyClassifier().fit(X_cleanish, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
